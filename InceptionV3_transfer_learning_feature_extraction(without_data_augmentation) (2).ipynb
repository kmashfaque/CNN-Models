{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTaxD78uGoFd"
   },
   "outputs": [],
   "source": [
    "# # !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9bqolnIG7oz",
    "outputId": "4b9c1ce1-24f8-4f1e-8717-74edbfbe4bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading dogs-vs-cats.zip to /content\n",
      " 99% 1.06G/1.06G [00:07<00:00, 141MB/s]\n",
      "100% 1.06G/1.06G [00:07<00:00, 162MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !kaggle datasets download -d salader/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q9ZleRYeG9Hi"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/monkeypox.zip', 'r')\n",
    "zip_ref.extractall('/content')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G_WZ1RAxG_FX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9QDbgfKINH4",
    "outputId": "7f08ead5-9580-498b-9345-40c6c37a6d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# conv_base = InceptionV3(\n",
    "#     weights='imagenet',\n",
    "#     include_top = False,\n",
    "#     input_shape=(224,224,3)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3s2Mx8eIoZ1"
   },
   "source": [
    "# Reduce Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,  # Reduce learning rate by a factor of 0.2\n",
    "    patience=3,  # Wait 3 epochs before reducing\n",
    "    min_lr=1e-6  # Minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatively, use Cosine Decay or Exponential Decay for smooth learning rate reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t_wjp7VEIq31"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Load base model\n",
    "conv_base = InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "# Unfreeze top 30 layers of InceptionV3\n",
    "for layer in conv_base.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Freeze all layers initially\n",
    "# conv_base.trainable = False\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(GlobalAveragePooling2D())  # ✅ THIS LINE FIXES THE SHAPE\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "0h3z_qlMJSFm",
    "outputId": "72f3eafc-4da5-4ffc-80fa-cf2b6562bb20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,327,585</span> (85.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,327,585\u001b[0m (85.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,293,153</span> (85.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,293,153\u001b[0m (85.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,432\u001b[0m (134.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5JMk4tGFKKNP"
   },
   "outputs": [],
   "source": [
    "# conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtA99DZrKRMA",
    "outputId": "be6e5f4a-3326-4eb1-c26d-96729c151656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2142 files belonging to 2 classes.\n",
      "Found 420 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,               # always normalize\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Apply only normalization to validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# generators\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = '/content/Fold1/Fold1/Fold1/Train',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(224,224)\n",
    ")\n",
    "\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = '/content/Fold1/Fold1/Fold1/Val',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below code is with the augmentation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras imoport layers\n",
    "\n",
    "# Define data augmentation as a keras Sequential model\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),  # Increase rotation\n",
    "    layers.RandomZoom(0.3),\n",
    "    layers.RandomTranslation(0.2, 0.2),\n",
    "    layers.RandomContrast(0.2),  # Add contrast adjustment\n",
    "    layers.RandomBrightness(0.2)  # Add brightness adjustment\n",
    "])\n",
    "# Load datasets from your directories (with your exact paths)\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='/content/Fold1/Fold1/Fold1/Train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)\n",
    ")\n",
    "\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='/content/Fold1/Fold1/Fold1/Val',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)\n",
    ")\n",
    "\n",
    "# Function to apply augmentation and normalization to training data\n",
    "def process_train(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0,1]\n",
    "    image = data_augmentation(image)            # Apply augmentation\n",
    "    return image, label\n",
    "\n",
    "# Function to normalize validation data only\n",
    "def process_val(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0,1]\n",
    "    return image, label\n",
    "\n",
    "# Apply the processing functions\n",
    "train_ds = train_ds.map(process_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.map(process_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kHZiMvDKiG-"
   },
   "source": [
    "# model with hp tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Iq1ThOEsRys"
   },
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=128, max_value=512, step=128),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', 1e-5, 1e-3, sampling='log')\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    directory='tuner_dir',\n",
    "    project_name='inceptionv3_tuning'\n",
    ")\n",
    "tuner.search(train_ds, validation_data=validation_ds, epochs=20)\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-4cmGF_9KoYx"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RHlI2SMK0bF",
    "outputId": "2f9577ed-0056-4fcf-e3d4-a14408c14864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m14/67\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:01\u001b[0m 16s/step - accuracy: 0.6053 - loss: 0.6710"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,epochs=20,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Compute additional metrics like AUC-ROC or confusion matrix to better understand model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwIF9jci1HFZ"
   },
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred_probs = []\n",
    "for images, labels in validation_ds:\n",
    "    preds = model.predict(images).flatten()\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred_probs.extend(preds)\n",
    "\n",
    "auc = roc_auc_score(y_true, y_pred_probs)\n",
    "print(f\"AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, (np.array(y_pred_probs) > 0.5).astype(int))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Training Curves\n",
    "#### Your current plotting code is fine, but ensure you're monitoring for overfitting. If the validation loss increases while training loss decreases, the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed = []\n",
    "    for point in points:\n",
    "        if smoothed:\n",
    "            smoothed.append(smoothed[-1] * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed.append(point)\n",
    "    return smoothed\n",
    "\n",
    "plt.plot(smooth_curve(history.history['accuracy']), color='red', label='train')\n",
    "plt.plot(smooth_curve(history.history['val_accuracy']), color='blue', label='validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(smooth_curve(history.history['loss']), color='red', label='train')\n",
    "plt.plot(smooth_curve(history.history['val_loss']), color='blue', label='validation')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdU3n2wKK3v1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2U4c7R4GeuyX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_-7jqfPOt12"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8nHA56qex6V"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in validation_ds:\n",
    "    preds = model.predict(images).flatten()\n",
    "    pred_labels = (preds > 0.5).astype(int)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(pred_labels)\n",
    "class_name=[\"monkeypox\",\"others\"]\n",
    "class_names = validation_ds.class_names  # ['monkeypox', 'others']\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_auUMRqsex3I"
   },
   "outputs": [],
   "source": [
    "# Load the Validation Dataset\n",
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "val_dir = '/content/Fold1/Fold1/Fold1/Test'\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    directory=val_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=32,\n",
    "    image_size=(150, 150)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9CEbCjpex0x"
   },
   "outputs": [],
   "source": [
    "# Normalize the Images (like you did for training)\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tensorflow.cast(image / 255.0, tensorflow.float32)\n",
    "    return image, label\n",
    "\n",
    "val_ds = val_ds.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9WSq8RsexyS"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh3sOiRlexvw",
    "outputId": "2ff13ab1-8b35-4f68-9567-65d802651ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      "Others: 1162\n",
      "Monkeypox: 980\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "train_dir = \"/content/Fold1/Fold1/Fold1/Train\"\n",
    "print(\"Train class counts:\")\n",
    "for label in os.listdir(train_dir):\n",
    "    count = len(os.listdir(os.path.join(train_dir, label)))\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYTpolCvextU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhNBJh17exqd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6h2Ol-DexoL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pJq1owrexlk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLZzdXMXexi5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "actbtYTSOxuJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
